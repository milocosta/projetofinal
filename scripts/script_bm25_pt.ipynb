{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install transformers\n",
    "!pip install unidecode\n",
    "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,faiss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import unidecode\n",
    "import os, glob, re, sys, random, unicodedata, collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import sent_tokenize , word_tokenize\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "## criando lista de stopwords\n",
    "STOP_WORDS = stopwords.words('portuguese') + list(string.punctuation)\n",
    "STOP_WORDS.append('\\n')\n",
    "\n",
    "## Importação do BERT - Hugginface\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForPreTraining, BertTokenizer, BertForSequenceClassification, pipeline\n",
    "import torch\n",
    "\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import FARMReader, TransformersReader, DensePassageRetriever, PreProcessor, BM25Retriever\n",
    "from haystack.document_stores import FAISSDocumentStore, ElasticsearchDocumentStore\n",
    "from haystack.pipelines import ExtractiveQAPipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9535e1ab789461f2081629280b4978e16d4b483e21b789a363bfb9cb460dd483"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
